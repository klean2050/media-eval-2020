{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to sort the tags in the training set (Jamendo+Music4All) by frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_tags(add_m4a = True):\n",
    "    \n",
    "    train_split_path = '../example_splits/jamendo_moodtheme-train.tsv'\n",
    "\n",
    "    train_tags = []\n",
    "\n",
    "    for line in open(train_split_path, 'r'):\n",
    "        tags = line.strip().split('\\t')[2:]\n",
    "        train_tags.extend(tags)\n",
    "    train_tags = train_tags[1:]\n",
    "\n",
    "    # Add the music4all instances to the Jamendo training set\n",
    "    if add_m4a:\n",
    "        m4a_split_path = '../example_splits/m4a_moodtheme-train.tsv'\n",
    "\n",
    "\n",
    "        for i, line in enumerate(open(m4a_split_path, 'r')):\n",
    "            if i > 0:\n",
    "                tags = line.strip().split('\\t')[1:]\n",
    "                train_tags.extend(tags)\n",
    "\n",
    "\n",
    "    sorted_train_tags = Counter(train_tags).most_common()\n",
    "    sorted_train_tags = [x[0].split('---')[-1] for x in sorted_train_tags]\n",
    "\n",
    "    sorted_counter_values = []\n",
    "\n",
    "    counter = Counter(train_tags)\n",
    "\n",
    "    for tag in sorted_train_tags:\n",
    "        tag = 'mood/theme---'+tag\n",
    "        sorted_counter_values.append(counter[tag])\n",
    "\n",
    "    return sorted_train_tags, sorted_counter_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate PR-AUC and ROC-AUC scores for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakdown_class_performance(gt, predictions):\n",
    "    \n",
    "    LABELS = ['action',  'adventure', 'advertising',  'background',  'ballad',  'calm',  'children',\n",
    " 'christmas',  'commercial',  'cool',  'corporate',  'dark',  'deep',  'documentary',  'drama',\n",
    " 'dramatic',  'dream',  'emotional',  'energetic',  'epic',  'fast',  'film',  'fun',  'funny',\n",
    " 'game',  'groovy',  'happy',  'heavy',  'holiday',  'hopeful',  'inspiring',  'love',  'meditative',\n",
    " 'melancholic',  'melodic',  'motivational',  'movie',  'nature',  'party',  'positive',  'powerful',\n",
    " 'relaxing', 'retro',  'romantic',  'sad',  'sexy',  'slow',  'soft',  'soundscape',  'space',  'sport',\n",
    " 'summer',  'trailer',  'travel',  'upbeat',  'uplifting']\n",
    "    \n",
    "    pr_aucs = []\n",
    "    roc_aucs = []\n",
    "    for i in range(len(LABELS)):\n",
    "        pr_aucs.append(metrics.average_precision_score(gt[:,i], predictions[:,i]))\n",
    "        roc_aucs.append(metrics.roc_auc_score(gt[:,i], predictions[:,i]))\n",
    "    class_df = pd.DataFrame(index=LABELS)\n",
    "    class_df['PR-AUC'] = pr_aucs\n",
    "    class_df['ROC-AUC'] = roc_aucs\n",
    "    \n",
    "    return class_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate the performance of a model given an array of predictions and a ground truth array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(groundtruth, predictions):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for average in ['macro', 'micro']:\n",
    "        results['ROC-AUC-' + average] = metrics.roc_auc_score(groundtruth, predictions, average=average)\n",
    "        results['PR-AUC-' + average] = metrics.average_precision_score(groundtruth, predictions, average=average)\n",
    "\n",
    "    for metric in results:\n",
    "        print(metric,'=', results[metric])\n",
    "        \n",
    "    # Split the tags into head, middle, and tail groups to further evaluate performance.\n",
    "    sorted_train_tags, sorted_counter_values = get_sorted_tags()\n",
    "\n",
    "    head = sorted_train_tags[:14] \n",
    "    middle = sorted_train_tags[14:41]\n",
    "    tail = sorted_train_tags[41:]\n",
    "    \n",
    "    class_df = breakdown_class_performance(groundtruth, predictions)\n",
    "    \n",
    "    label_splits = {'head':head,'middle':middle,'tail':tail}\n",
    "    print('\\n')\n",
    "    for labels in label_splits:\n",
    "        print(labels+':')\n",
    "        print('PR-AUC:',np.mean(class_df.loc[label_splits[labels]]['PR-AUC']))\n",
    "        print('ROC-AUC:',np.mean(class_df.loc[label_splits[labels]]['ROC-AUC']))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data:\n",
    "Jamendo + Music4All + MillionSongDataset\n",
    "\n",
    "Sampling: \n",
    "Class-aware resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation split:\n",
      "\n",
      "BCE:\n",
      "\n",
      "ROC-AUC-macro = 0.7438425478910712\n",
      "PR-AUC-macro = 0.11918333999238269\n",
      "ROC-AUC-micro = 0.7691079033761603\n",
      "PR-AUC-micro = 0.12449050886011888\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.16789564663609804\n",
      "ROC-AUC: 0.7494754299190404\n",
      "middle:\n",
      "PR-AUC: 0.10933731605911336\n",
      "ROC-AUC: 0.7364935752762615\n",
      "tail:\n",
      "PR-AUC: 0.09144136353813319\n",
      "ROC-AUC: 0.7518133420382912\n",
      "\n",
      "Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.74385916691003\n",
      "PR-AUC-macro = 0.11931738888595755\n",
      "ROC-AUC-micro = 0.7755937972019219\n",
      "PR-AUC-micro = 0.12205291663665638\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.16747985418212882\n",
      "ROC-AUC: 0.7455882166205428\n",
      "middle:\n",
      "PR-AUC: 0.10652248164160451\n",
      "ROC-AUC: 0.7299556082583826\n",
      "tail:\n",
      "PR-AUC: 0.09739658764936647\n",
      "ROC-AUC: 0.7672717927531832\n",
      "\n",
      "CB Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7418012871789789\n",
      "PR-AUC-macro = 0.11633239323733725\n",
      "ROC-AUC-micro = 0.7787111870158601\n",
      "PR-AUC-micro = 0.12254027869586102\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.1628802390216409\n",
      "ROC-AUC: 0.7454891564662888\n",
      "middle:\n",
      "PR-AUC: 0.10672670055916299\n",
      "ROC-AUC: 0.7366850759787315\n",
      "tail:\n",
      "PR-AUC: 0.0901779839927009\n",
      "ROC-AUC: 0.7475684560046013\n",
      "\n",
      "DB Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7403381822336363\n",
      "PR-AUC-macro = 0.11608451244178093\n",
      "ROC-AUC-micro = 0.7780578849150461\n",
      "PR-AUC-micro = 0.12168334639160205\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.16440588166909356\n",
      "ROC-AUC: 0.7446551930955072\n",
      "middle:\n",
      "PR-AUC: 0.10488113506552041\n",
      "ROC-AUC: 0.7342802759844445\n",
      "tail:\n",
      "PR-AUC: 0.09115064710689134\n",
      "ROC-AUC: 0.7472132033444355\n",
      "\n",
      "\n",
      "Test split:\n",
      "\n",
      "BCE:\n",
      "\n",
      "ROC-AUC-macro = 0.7585877689216434\n",
      "PR-AUC-macro = 0.14819191691162417\n",
      "ROC-AUC-micro = 0.8024188816316278\n",
      "PR-AUC-micro = 0.1638885393003156\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.16761147007003263\n",
      "ROC-AUC: 0.7535958954125047\n",
      "middle:\n",
      "PR-AUC: 0.16613139672943783\n",
      "ROC-AUC: 0.757713754407674\n",
      "tail:\n",
      "PR-AUC: 0.09777593695837833\n",
      "ROC-AUC: 0.7648200769886511\n",
      "\n",
      "Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7625182725333648\n",
      "PR-AUC-macro = 0.14576632007142878\n",
      "ROC-AUC-micro = 0.8043300791548991\n",
      "PR-AUC-micro = 0.1602537433512471\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.17343508102975871\n",
      "ROC-AUC: 0.7443153647264609\n",
      "middle:\n",
      "PR-AUC: 0.1575918613998641\n",
      "ROC-AUC: 0.7585036290361524\n",
      "tail:\n",
      "PR-AUC: 0.09865616878580381\n",
      "ROC-AUC: 0.7867340114481238\n",
      "\n",
      "CB Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7600107537410639\n",
      "PR-AUC-macro = 0.14139508998884776\n",
      "ROC-AUC-micro = 0.8049541519744994\n",
      "PR-AUC-micro = 0.16467249467124276\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.1689864175267006\n",
      "ROC-AUC: 0.7469816341787602\n",
      "middle:\n",
      "PR-AUC: 0.15467651652497866\n",
      "ROC-AUC: 0.7595415664312889\n",
      "tail:\n",
      "PR-AUC: 0.09173661652181606\n",
      "ROC-AUC: 0.7730158024901422\n",
      "\n",
      "DB Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.759239082656926\n",
      "PR-AUC-macro = 0.14714512336813637\n",
      "ROC-AUC-micro = 0.8048342351903337\n",
      "PR-AUC-micro = 0.1672888519481529\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.1724873043885964\n",
      "ROC-AUC: 0.7481079504756947\n",
      "middle:\n",
      "PR-AUC: 0.16043975918125414\n",
      "ROC-AUC: 0.7594796197412775\n",
      "tail:\n",
      "PR-AUC: 0.09956207661876156\n",
      "ROC-AUC: 0.7691951726075758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the model predictions and the ground truth array.\n",
    "\n",
    "predictions_path = '../predictions/all_training_data/class_aware_resampling'\n",
    "\n",
    "print('Validation split:\\n')\n",
    "split = 'validation'\n",
    "\n",
    "ground_truth = np.load('../predictions/'+ split +'_ground_truth.npy')\n",
    "\n",
    "bce = np.load(os.path.join(predictions_path, split,'bce_predictions.npy'))\n",
    "focal = np.load(os.path.join(predictions_path, split,'focal_loss_predictions.npy'))\n",
    "cb = np.load(os.path.join(predictions_path, split,'cb_focal_loss_predictions.npy'))\n",
    "db = np.load(os.path.join(predictions_path, split,'db_focal_loss_predictions.npy'))\n",
    "\n",
    "# Evaluate individual model performance:\n",
    "\n",
    "print('BCE:\\n')\n",
    "evaluate(ground_truth, bce)\n",
    "\n",
    "print('Focal loss:\\n')\n",
    "evaluate(ground_truth, focal)\n",
    "\n",
    "print('CB Focal loss:\\n')\n",
    "evaluate(ground_truth, cb)\n",
    "\n",
    "print('DB Focal loss:\\n')\n",
    "evaluate(ground_truth, db)\n",
    "\n",
    "\n",
    "print('\\nTest split:\\n')\n",
    "split = 'test'\n",
    "\n",
    "ground_truth = np.load('../predictions/'+ split +'_ground_truth.npy')\n",
    "\n",
    "bce = np.load(os.path.join(predictions_path, split,'bce_predictions.npy'))\n",
    "focal = np.load(os.path.join(predictions_path, split,'focal_loss_predictions.npy'))\n",
    "cb = np.load(os.path.join(predictions_path, split,'cb_focal_loss_predictions.npy'))\n",
    "db = np.load(os.path.join(predictions_path, split,'db_focal_loss_predictions.npy'))\n",
    "\n",
    "# Evaluate individual model performance:\n",
    "\n",
    "print('BCE:\\n')\n",
    "evaluate(ground_truth, bce)\n",
    "\n",
    "print('Focal loss:\\n')\n",
    "evaluate(ground_truth, focal)\n",
    "\n",
    "print('CB Focal loss:\\n')\n",
    "evaluate(ground_truth, cb)\n",
    "\n",
    "print('DB Focal loss:\\n')\n",
    "evaluate(ground_truth, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data:\n",
    "Jamendo + Music4All + MillionSongDataset\n",
    "\n",
    "Sampling: \n",
    "Standard sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation split:\n",
      "\n",
      "BCE:\n",
      "\n",
      "ROC-AUC-macro = 0.7482499064649113\n",
      "PR-AUC-macro = 0.12382037205503996\n",
      "ROC-AUC-micro = 0.7780083280731263\n",
      "PR-AUC-micro = 0.13407422714862569\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.17782289429400758\n",
      "ROC-AUC: 0.7503896921470677\n",
      "middle:\n",
      "PR-AUC: 0.11791856107372602\n",
      "ROC-AUC: 0.749013978451403\n",
      "tail:\n",
      "PR-AUC: 0.08404127773170196\n",
      "ROC-AUC: 0.7448774435858794\n",
      "\n",
      "Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7530997642135144\n",
      "PR-AUC-macro = 0.12297864187890421\n",
      "ROC-AUC-micro = 0.787295326915569\n",
      "PR-AUC-micro = 0.13687406865289184\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.17804579484506072\n",
      "ROC-AUC: 0.748570113396192\n",
      "middle:\n",
      "PR-AUC: 0.11917888964612187\n",
      "ROC-AUC: 0.7506981641898473\n",
      "tail:\n",
      "PR-AUC: 0.07842218646283297\n",
      "ROC-AUC: 0.761650318352283\n",
      "\n",
      "CB Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7494903498189812\n",
      "PR-AUC-macro = 0.1223528433536589\n",
      "ROC-AUC-micro = 0.7888203556294552\n",
      "PR-AUC-micro = 0.13521827593650904\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.16897877465654032\n",
      "ROC-AUC: 0.745088417978656\n",
      "middle:\n",
      "PR-AUC: 0.1133868125653233\n",
      "ROC-AUC: 0.7474385558936372\n",
      "tail:\n",
      "PR-AUC: 0.09497416288997375\n",
      "ROC-AUC: 0.7572920486022368\n",
      "\n",
      "DB Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7454449641081433\n",
      "PR-AUC-macro = 0.12037887207750117\n",
      "ROC-AUC-micro = 0.7837017526144741\n",
      "PR-AUC-micro = 0.13393584513855092\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.17695697307361305\n",
      "ROC-AUC: 0.7400976375792837\n",
      "middle:\n",
      "PR-AUC: 0.10903850353887741\n",
      "ROC-AUC: 0.746213788482386\n",
      "tail:\n",
      "PR-AUC: 0.0879853078506529\n",
      "ROC-AUC: 0.7490519183281087\n",
      "\n",
      "\n",
      "Test split:\n",
      "\n",
      "BCE:\n",
      "\n",
      "ROC-AUC-macro = 0.7655189120045323\n",
      "PR-AUC-macro = 0.15012710634774581\n",
      "ROC-AUC-micro = 0.8046724989464487\n",
      "PR-AUC-micro = 0.17389221153066853\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.1789034130929766\n",
      "ROC-AUC: 0.7587232720006389\n",
      "middle:\n",
      "PR-AUC: 0.16261696743573198\n",
      "ROC-AUC: 0.7661756791930153\n",
      "tail:\n",
      "PR-AUC: 0.10078747009382186\n",
      "ROC-AUC: 0.7706793284022296\n",
      "\n",
      "Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7782635516386016\n",
      "PR-AUC-macro = 0.15611355860480874\n",
      "ROC-AUC-micro = 0.8176904191407116\n",
      "PR-AUC-micro = 0.1816887158225965\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.17430994579936152\n",
      "ROC-AUC: 0.7601162911797326\n",
      "middle:\n",
      "PR-AUC: 0.17087893200595208\n",
      "ROC-AUC: 0.77592786157714\n",
      "tail:\n",
      "PR-AUC: 0.1125525917678348\n",
      "ROC-AUC: 0.7994052368441769\n",
      "\n",
      "CB Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7729700497784106\n",
      "PR-AUC-macro = 0.1532354229778677\n",
      "ROC-AUC-micro = 0.8147169152352189\n",
      "PR-AUC-micro = 0.1823997228036829\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.1732901297085754\n",
      "ROC-AUC: 0.7588042463398096\n",
      "middle:\n",
      "PR-AUC: 0.17033039334403183\n",
      "ROC-AUC: 0.7686036799801679\n",
      "tail:\n",
      "PR-AUC: 0.1037467500367785\n",
      "ROC-AUC: 0.7940509319579415\n",
      "\n",
      "DB Focal loss:\n",
      "\n",
      "ROC-AUC-macro = 0.7683537309986824\n",
      "PR-AUC-macro = 0.1534133777050317\n",
      "ROC-AUC-micro = 0.8099461022436419\n",
      "PR-AUC-micro = 0.17569206134093276\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.17317981745525657\n",
      "ROC-AUC: 0.7568774338594879\n",
      "middle:\n",
      "PR-AUC: 0.16999830781994252\n",
      "ROC-AUC: 0.7643885323570644\n",
      "tail:\n",
      "PR-AUC: 0.1051118263979823\n",
      "ROC-AUC: 0.7862022992168438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the model predictions and the ground truth array.\n",
    "\n",
    "predictions_path = '../predictions/all_training_data/standard_sampling'\n",
    "\n",
    "print('Validation split:\\n')\n",
    "split = 'validation'\n",
    "\n",
    "ground_truth = np.load('../predictions/'+ split +'_ground_truth.npy')\n",
    "\n",
    "bce = np.load(os.path.join(predictions_path, split,'bce_predictions.npy'))\n",
    "focal = np.load(os.path.join(predictions_path, split,'focal_loss_predictions.npy'))\n",
    "cb = np.load(os.path.join(predictions_path, split,'cb_focal_loss_predictions.npy'))\n",
    "db = np.load(os.path.join(predictions_path, split,'db_focal_loss_predictions.npy'))\n",
    "\n",
    "# Evaluate individual model performance:\n",
    "\n",
    "print('BCE:\\n')\n",
    "evaluate(ground_truth, bce)\n",
    "\n",
    "print('Focal loss:\\n')\n",
    "evaluate(ground_truth, focal)\n",
    "\n",
    "print('CB Focal loss:\\n')\n",
    "evaluate(ground_truth, cb)\n",
    "\n",
    "print('DB Focal loss:\\n')\n",
    "evaluate(ground_truth, db)\n",
    "\n",
    "\n",
    "print('\\nTest split:\\n')\n",
    "split = 'test'\n",
    "\n",
    "ground_truth = np.load('../predictions/'+ split +'_ground_truth.npy')\n",
    "\n",
    "bce = np.load(os.path.join(predictions_path, split,'bce_predictions.npy'))\n",
    "focal = np.load(os.path.join(predictions_path, split,'focal_loss_predictions.npy'))\n",
    "cb = np.load(os.path.join(predictions_path, split,'cb_focal_loss_predictions.npy'))\n",
    "db = np.load(os.path.join(predictions_path, split,'db_focal_loss_predictions.npy'))\n",
    "\n",
    "# Evaluate individual model performance:\n",
    "\n",
    "print('BCE:\\n')\n",
    "evaluate(ground_truth, bce)\n",
    "\n",
    "print('Focal loss:\\n')\n",
    "evaluate(ground_truth, focal)\n",
    "\n",
    "print('CB Focal loss:\\n')\n",
    "evaluate(ground_truth, cb)\n",
    "\n",
    "print('DB Focal loss:\\n')\n",
    "evaluate(ground_truth, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble the four models trained using standard sampling the and save the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC-macro = 0.7812286699703872\n",
      "PR-AUC-macro = 0.1609607384174659\n",
      "ROC-AUC-micro = 0.8197803684777436\n",
      "PR-AUC-micro = 0.1866509359262184\n",
      "\n",
      "\n",
      "head:\n",
      "PR-AUC: 0.18156240462417053\n",
      "ROC-AUC: 0.7669046356293754\n",
      "middle:\n",
      "PR-AUC: 0.17924425900300184\n",
      "ROC-AUC: 0.7776673708795513\n",
      "tail:\n",
      "PR-AUC: 0.10882217957057705\n",
      "ROC-AUC: 0.8010081070521696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_predictions = (bce+focal+cb+db)/4\n",
    "\n",
    "evaluate(ground_truth, ensemble_predictions)\n",
    "\n",
    "np.save('ensemble_predictions.npy', ensemble_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
