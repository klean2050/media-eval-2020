{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we analyze our best performing ensemble model in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = [\n",
    "'mood/theme---action',\n",
    "'mood/theme---adventure',\n",
    "'mood/theme---advertising',\n",
    "'mood/theme---background',\n",
    "'mood/theme---ballad',\n",
    "'mood/theme---calm',\n",
    "'mood/theme---children',\n",
    "'mood/theme---christmas',\n",
    "'mood/theme---commercial',\n",
    "'mood/theme---cool',\n",
    "'mood/theme---corporate',\n",
    "'mood/theme---dark',\n",
    "'mood/theme---deep',\n",
    "'mood/theme---documentary',\n",
    "'mood/theme---drama',\n",
    "'mood/theme---dramatic',\n",
    "'mood/theme---dream',\n",
    "'mood/theme---emotional',\n",
    "'mood/theme---energetic',\n",
    "'mood/theme---epic',\n",
    "'mood/theme---fast',\n",
    "'mood/theme---film',\n",
    "'mood/theme---fun',\n",
    "'mood/theme---funny',\n",
    "'mood/theme---game',\n",
    "'mood/theme---groovy',\n",
    "'mood/theme---happy',\n",
    "'mood/theme---heavy',\n",
    "'mood/theme---holiday',\n",
    "'mood/theme---hopeful',\n",
    "'mood/theme---inspiring',\n",
    "'mood/theme---love',\n",
    "'mood/theme---meditative',\n",
    "'mood/theme---melancholic',\n",
    "'mood/theme---melodic',\n",
    "'mood/theme---motivational',\n",
    "'mood/theme---movie',\n",
    "'mood/theme---nature',\n",
    "'mood/theme---party',\n",
    "'mood/theme---positive',\n",
    "'mood/theme---powerful',\n",
    "'mood/theme---relaxing',\n",
    "'mood/theme---retro',\n",
    "'mood/theme---romantic',\n",
    "'mood/theme---sad',\n",
    "'mood/theme---sexy',\n",
    "'mood/theme---slow',\n",
    "'mood/theme---soft',\n",
    "'mood/theme---soundscape',\n",
    "'mood/theme---space',\n",
    "'mood/theme---sport',\n",
    "'mood/theme---summer',\n",
    "'mood/theme---trailer',\n",
    "'mood/theme---travel',\n",
    "'mood/theme---upbeat',\n",
    "'mood/theme---uplifting']\n",
    "\n",
    "TAGS = [tag.split('---')[-1] for tag in TAGS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a heirarchy for the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_subsets = {}\n",
    "tag_subsets['positive'] = {}\n",
    "\n",
    "tag_subsets['positive']['low'] = ['calm',\n",
    "                                    'cool',\n",
    "                                    'emotional',\n",
    "                                    'hopeful',\n",
    "                                    'meditative',\n",
    "                                    'relaxing',\n",
    "                                    'slow',\n",
    "                                    'soft']\n",
    "\n",
    "tag_subsets['positive']['neutral'] = ['fun',\n",
    "                                        'funny',\n",
    "                                        'groovy',\n",
    "                                        'happy',\n",
    "                                        'inspiring',\n",
    "                                        'love',\n",
    "                                        'motivational',\n",
    "\n",
    "                                        'positive',\n",
    "                                        'powerful',\n",
    "                                        'sexy']\n",
    "\n",
    "tag_subsets['positive']['high'] = ['energetic',\n",
    "                                    'epic',\n",
    "                                    'fast',\n",
    "                                    'party',\n",
    "                                    'romantic',\n",
    "                                    'upbeat',\n",
    "                                    'uplifting']\n",
    "\n",
    "\n",
    "\n",
    "tag_subsets['negative'] = {}\n",
    "\n",
    "tag_subsets['negative']['sad'] = ['ballad',\n",
    "                                    'melancholic',\n",
    "                                    'sad']\n",
    "\n",
    "tag_subsets['negative']['other'] = ['dark',\n",
    "                                    'drama',\n",
    "                                    'dramatic',\n",
    "                                    'heavy']\n",
    "\n",
    "\n",
    "\n",
    "tag_subsets['misc'] = {}\n",
    "\n",
    "\n",
    "tag_subsets['misc']['media'] = ['advertising',\n",
    "                            'commercial',\n",
    "                            'documentary',\n",
    "                            'film',\n",
    "                            'game',\n",
    "                            'movie',\n",
    "                            'sport',\n",
    "                            'trailer']\n",
    "\n",
    "tag_subsets['misc']['seasonal'] = ['christmas',\n",
    "                            'holiday',\n",
    "                            'summer']\n",
    "\n",
    "tag_subsets['misc']['other'] = ['action',\n",
    "                            'adventure',\n",
    "                            'background',\n",
    "                            'children',\n",
    "                            'corporate',\n",
    "                            'deep',\n",
    "                            'dream',\n",
    "                            'melodic',\n",
    "                            'nature',\n",
    "                            'retro',\n",
    "                            'soundscape',\n",
    "                            'space',\n",
    "                            'travel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate the performance of the model given an array of predictions and a ground truth array for the given label subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(groundtruth, predictions):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for average in ['macro']:\n",
    "        results['ROC-AUC-' + average] = metrics.roc_auc_score(groundtruth, predictions, average=average)\n",
    "        results['PR-AUC-' + average] = metrics.average_precision_score(groundtruth, predictions, average=average)\n",
    "\n",
    "    for metric in results:\n",
    "        print(metric,'=', results[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a subset of labels, returning the index from the alphabetized tags list, TAGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_indices(tag_subset):\n",
    "    \n",
    "    indices = []\n",
    "    for tag in tag_subset:\n",
    "        \n",
    "        indices.append(TAGS.index(tag))\n",
    "        \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the predicitions and ground truth arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions = np.load('../predictions/ensemble_predictions_all_data.npy')\n",
    "\n",
    "ground_truth = np.load('../predictions/test_ground_truth.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive valence, low arousal:\n",
      "\n",
      "ROC-AUC-macro = 0.7223092792897011\n",
      "PR-AUC-macro = 0.09213266760520744\n",
      "\n",
      "\n",
      "Positive valence, neutral arousal:\n",
      "\n",
      "ROC-AUC-macro = 0.7996187124136899\n",
      "PR-AUC-macro = 0.13360330464190667\n",
      "\n",
      "\n",
      "Positive valence, high arousal:\n",
      "\n",
      "ROC-AUC-macro = 0.8222218914217266\n",
      "PR-AUC-macro = 0.1384584412347932\n",
      "\n",
      "\n",
      "Negative valence, sad synonyms:\n",
      "\n",
      "ROC-AUC-macro = 0.7442986610443626\n",
      "PR-AUC-macro = 0.08621283887209014\n",
      "\n",
      "\n",
      "Negative valence, other labels:\n",
      "\n",
      "ROC-AUC-macro = 0.7891849712855972\n",
      "PR-AUC-macro = 0.17242628691566173\n",
      "\n",
      "\n",
      "Media-related labels:\n",
      "\n",
      "ROC-AUC-macro = 0.7825324486968115\n",
      "PR-AUC-macro = 0.1774384810591242\n",
      "\n",
      "\n",
      "Season/holiday labels:\n",
      "\n",
      "ROC-AUC-macro = 0.8673664253047336\n",
      "PR-AUC-macro = 0.3993026561460615\n",
      "\n",
      "\n",
      "All other labels:\n",
      "\n",
      "ROC-AUC-macro = 0.7666612450900706\n",
      "PR-AUC-macro = 0.18505679956028598\n"
     ]
    }
   ],
   "source": [
    "print('Positive valence, low arousal:\\n')\n",
    "indices = get_label_indices(tag_subsets['positive']['low'])\n",
    "evaluate(ground_truth[:,indices], best_predictions[:,indices])\n",
    "\n",
    "\n",
    "print('\\n\\nPositive valence, neutral arousal:\\n')\n",
    "indices = get_label_indices(tag_subsets['positive']['neutral'])\n",
    "evaluate(ground_truth[:,indices], best_predictions[:,indices])\n",
    "\n",
    "\n",
    "print('\\n\\nPositive valence, high arousal:\\n')\n",
    "indices = get_label_indices(tag_subsets['positive']['high'])\n",
    "evaluate(ground_truth[:,indices], best_predictions[:,indices])\n",
    "\n",
    "\n",
    "print('\\n\\nNegative valence, sad synonyms:\\n')\n",
    "indices = get_label_indices(tag_subsets['negative']['sad'])\n",
    "evaluate(ground_truth[:,indices], best_predictions[:,indices])\n",
    "\n",
    "\n",
    "print('\\n\\nNegative valence, other labels:\\n')\n",
    "indices = get_label_indices(tag_subsets['negative']['other'])\n",
    "evaluate(ground_truth[:,indices], best_predictions[:,indices])\n",
    "\n",
    "\n",
    "print('\\n\\nMedia-related labels:\\n')\n",
    "indices = get_label_indices(tag_subsets['misc']['media'])\n",
    "evaluate(ground_truth[:,indices], best_predictions[:,indices])\n",
    "\n",
    "\n",
    "print('\\n\\nSeason/holiday labels:\\n')\n",
    "indices = get_label_indices(tag_subsets['misc']['seasonal'])\n",
    "evaluate(ground_truth[:,indices], best_predictions[:,indices])\n",
    "\n",
    "\n",
    "print('\\n\\nAll other labels:\\n')\n",
    "indices = get_label_indices(tag_subsets['misc']['other'])\n",
    "evaluate(ground_truth[:,indices], best_predictions[:,indices])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
